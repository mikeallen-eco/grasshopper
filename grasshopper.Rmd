# load libraries and data

download worldclim (updated to use terra and sf)
https://gis.stackexchange.com/questions/227585/using-r-to-extract-data-from-worldclim

citation for grasshopper occurences:
GBIF.org (27 July 2023) GBIF Occurrence Download  https://doi.org/10.15468/dl.dqxb4h
```{r}
library(terra)
library(sf)
library(dplyr)
library(tidyr)
library(forcats)
library(ggplot2)
library(geodata)

# grasshopper

data_sources <- read.csv("data/datasets_download_usage_0118912-230530130749713.tsv", sep = "\t")
g <- read.csv("data/0118912-230530130749713.csv", sep = "\t") %>%
  rename(lat = decimalLatitude, lon = decimalLongitude) %>%
  mutate(dupcheck = paste0(lat,lon),
         dup = duplicated(dupcheck)) %>%
  filter(dup == FALSE) %>% 
  dplyr::select(-dupcheck, -dup)

# worldclim
r <- geodata::worldclim_global(var = "bio", res = 5, path = "data/")

points <- g %>%
  dplyr::select(gbifID, lat, lon) %>%
  st_as_sf(., coords = c("lon", "lat"))

# plot points
plot(r[[1]], xlim = c(-120, -50), ylim = c(15, 50))
plot(points, add = TRUE)

# remove 3 observations that were extreme western outliers (at least one of which was a disputed ID)
points <- g %>%
  filter(lon > -109) %>%
  dplyr::select(gbifID, lat, lon) %>%
  st_as_sf(., coords = c("lon", "lat"))

# plot trimmed points
plot(r[[1]], xlim = c(-120, -50), ylim = c(15, 50))
plot(points, add = TRUE)

values <- terra::extract(r, points)

df <- cbind.data.frame(dplyr::select(filter(g, lon > -109), gbifID, lat, lon), values)

df

```
# Build maxent model using dismo
build a maxent model in dismo
https://rdrr.io/cran/dismo/man/maxent.html
https://github.com/shandongfx/workshop_maxent_R/blob/master/code/Appendix1_case_study.md
Note: to make maxent work, I had to download a version of R that matched the build of Java that was installed. 
```{r}
library(dismo)
library(rJava)
maxent()

points_sp <- as(points, "Spatial")

# thin occ data (keep one occurrence point per cell)
cells <- terra::cellFromXY(raster(r[[1]]), points_sp)
dups <- duplicated(cells)
occ_final <- points_sp[!dups, ] %>%
  st_as_sf(., crs = st_crs(clim))
cat(nrow(points_sp) - nrow(occ_final), "records are removed")
st_crs(occ_final) <- st_crs(clim)

# plot the first climatic layer (or replace [[1]] with any
# nth number of the layer of interest from the raster stack).
clim <- r; rm(r)
plot(clim[[1]], xlim = c(-109, -50), ylim = c(15, 50))

# plot the final occurrence data on the environmental layer
plot(occ_final, add = T, col = "red")  # the 'add=T' tells R to put the incoming data on the existing layer

# this creates a 400 km
# that equates to about a 4-decimal-degree buffer per https://www.johndcook.com/how_big_is_a_degree.html
# occurrence data
occ_buff <- st_buffer(occ_final, dist = 400000) %>%
  st_union()

# plot the first element ([[1]]) in the raster stack
plot(clim[[1]], xlim = c(-109, -50), ylim = c(15, 50))

plot(occ_buff, add = T, col = "blue")  # adds buffer polygon to the plot
plot(occ_final, add = T, col = "red")  # adds occurrence data to the plot

# crop study area to a manageable extent (rectangle shaped)
studyArea <- terra::crop(clim, ext(as(occ_buff, "Spatial")))  

# the 'study area' created by extracting the buffer area from the raster stack
studyArea <- mask(studyArea, vect(occ_buff))
# output will still be a raster stack, just of the study area

# save the new study area rasters as ascii
writeRaster(studyArea,
            # a series of names for output files
            filename=paste0("../data/studyarea/",names(studyArea),".asc"), 
            format="ascii", ## the output format
            bylayer=TRUE, ## this will save a series of layers
            overwrite=T)

# select background points from this buffered area; when the number provided 
# to set.seed() function, the same random sample will be selected in the next line			
# use this code before the sampleRandom function every time, if you want to get
# the same "random samples"
set.seed(2) 
bg <- sampleRandom(x=studyArea,
                   size=1000,
                   na.rm=T, #removes the 'Not Applicable' points  
                   sp=T) # return spatial points 

bg <- spatSample(x = studyArea,
                 size = 1000,
                 method = "random",
                 as.points = TRUE,
                 na.rm = TRUE) %>%
  as(., "Spatial")

plot(studyArea[[1]])
# add the background points to the plotted raster
plot(bg,add=T) 
# add the occurrence data to the plotted raster
plot(occ_final,add=T,col="red")

# get the same random sample for training and testing
set.seed(2)

# randomly select 50% for training
selected <- sample(1:nrow(occ_final), nrow(occ_final) * 0.75)

occ_train <- occ_final[selected, ]  # this is the selection to be used for model training
occ_test <- occ_final[-selected, ]  # this is the opposite of the selection which will be used for model testing

# extracting env conditions for training occ from the raster
# stack; a data frame is returned (i.e multiple columns)
p <- extract(clim, occ_train)
# env conditions for testing occ
p_test <- extract(clim, occ_test)
# extracting env conditions for background
a <- extract(clim, vect(bg))

# repeat the number 1 as many numbers as the number of rows
# in p, and repeat 0 as the rows of background points
pa <- c(rep(1, nrow(p)), rep(0, nrow(a)))

# (rep(1,nrow(p)) creating the number of rows as the p data
# set to have the number '1' as the indicator for presence;
# rep(0,nrow(a)) creating the number of rows as the a data
# set to have the number '0' as the indicator for absence;
# the c combines these ones and zeros into a new vector that
# can be added to the Maxent table data frame with the
# environmental attributes of the presence and absence
# locations
pder <- as.data.frame(rbind(p, a))

# train Maxent with spatial data
# mod <- maxent(x=clim,p=occ_train)

# train Maxent with tabular data
mod <- maxent(x=pder[2:20], ## env conditions
              p=pa,   ## 1:presence or 0:absence

              path=paste0("./output/maxent_outputs"), ## folder for maxent output; 
              # if we do not specify a folder R will put the results in a temp file, 
              # and it gets messy to read those. . .
              args=c("responsecurves") ## parameter specification
              )
# the maxent functions runs a model in the default settings. To change these parameters,
# you have to tell it what you want...i.e. response curves or the type of features

# view the maxent model in a html brower
show(mod)

# view detailed results
mod@results

# example 1, project to study area [raster]
ped1 <- predict(mod, studyArea)  # studyArea is the clipped rasters 
plot(ped1)  # plot the continuous prediction

# example 2, project to the world ped2 <- predict(mod,clim)
# plot(ped2)

# example 3, project with training occurrences [dataframes]
ped3 <- predict(mod, p)
head(ped3)

hist(ped3)  # creates a histogram of the prediction

# using 'training data' to evaluate p & a are dataframe/s
# (the p and a are the training presence and background
# points)
mod_eval_train <- dismo::evaluate(p = p, a = a, model = mod)
print(mod_eval_train)

mod_eval_test <- dismo::evaluate(p = p_test, a = a, model = mod)
print(mod_eval_test)  # training AUC may be higher than testing AUC

# calculate thresholds of models
thd1 <- threshold(mod_eval_train, "no_omission")  # 0% omission rate 
thd2 <- threshold(mod_eval_train, "spec_sens")  # highest TSS

# plotting points that are above the previously calculated
# thresholded value
plot(ped1 >= thd1)
# plot(ped1 >= thd2)
plot(occ_final, add = T)


```
# future climate data
https://www.worldclim.org/data/cmip6/cmip6_clim5m.html
```{r}



```

